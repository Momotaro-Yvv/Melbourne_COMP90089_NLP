{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58958ec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/abchapman93/Melbourne_COMP90089_NLP/releases/download/fall_2022/melbourne_comp90089_nlp-0.0.0.1.tar.gz\n",
      "  Downloading https://github.com/abchapman93/Melbourne_COMP90089_NLP/releases/download/fall_2022/melbourne_comp90089_nlp-0.0.0.1.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting medspacy==0.2.0.0\n",
      "  Using cached medspacy-0.2.0.0.tar.gz (111 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting spacy<3.2.0,>=3.1.3\n",
      "  Using cached spacy-3.1.6.tar.gz (1.0 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting PyRuSH>=1.0.3.5\n",
      "  Using cached PyRuSH-1.0.4.tar.gz (45 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/h9/vzydyw897w32tn4wvn7c8tkw0000gn/T/pip-install-f5pmc9vd/pyrush_2f6021d486954e608790b7a6bfe3cd89/setup.py\", line 5, in <module>\n",
      "  \u001b[31m   \u001b[0m     from Cython.Build import cythonize, build_ext\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'Cython'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/abchapman93/Melbourne_COMP90089_NLP/releases/download/fall_2022/melbourne_comp90089_nlp-0.0.0.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4993c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from melbourne_comp90089_nlp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e07e76",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "When people talk about data science, they are often talking about **Artificial Intelligence (AI)**. Broadly speaking, AI is a set of techniques for generating insights or imitating human decision-making using large datasets (\"big data\"). Most AI systems use **machine learning** which are algorithms that learn directly from data with minimal manual input. But some AI systems also utilize human knowledge in the form of complex rules. \n",
    "\n",
    "The first part of this module will focus on **Natural Language Processing (NLP)**, a form of AI which deals with text data. We'll learn what goes into an NLP system and build a model which classifies radiology reports for pneumonia. Then we'll build a small **supervised machine learning** system to predict whether a patient has diabetes.\n",
    "\n",
    "Let's begin by learning about some new types of data in the EHR.\n",
    "\n",
    "## Unstructured Data in the EHR\n",
    "When you see a doctor, they enter your information into the EHR in a few different ways. We've already seen some examples like:\n",
    "- ICD-9/10 codes\n",
    "- Numeric vital measurements\n",
    "- Flags for abnormal tests\n",
    "\n",
    "These are all **structured** data elements: the values are either numeric values or discrete elements with distinct, concrete meaning. Importantly, these values are *computable*: we can take the average of numeric vital measurements or count of ICD-10 codes.\n",
    "\n",
    "However, some forms of documentation are **unstructured**. Some examples are:\n",
    "- Videos\n",
    "- Radiology imaging\n",
    "- Full-text narratives\n",
    "\n",
    "Data forms like this are great for humans: they are easy to interpret and can include much more context and nuance than rigid, standardized data elements. However, they can't immediately be computed with. While a collection of pixels can be very meaningful to a radiologist, machines don't inherently have the ability to make sense of them.\n",
    "\n",
    "This presents a challenge to researchers since unstructured data accounts for a huge amount of the information stored in the EHR. While it would be great to utilize this information, we have to do a little extra work to make sense of it.\n",
    "\n",
    "## Clinical Narratives\n",
    "#### TODO\n",
    "Read the following excerpt of a discharge summary and then complete the quizzes that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15847bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Service: MEDICINE\n",
      "\n",
      "Chief Complaint:\n",
      "5 days worsening SOB, DOE\n",
      "\n",
      "History of Present Illness:\n",
      "Pt is a 63M w/ h/o metastatic carcinoid tumor, HTN, \n",
      "hyperlipidemia who reports increasing SOB and DOE starting about \n",
      "a month ago but worsening significantly within the last 5 days. \n",
      "It has recently gotten so bad he can barely get up out of a \n",
      "chair without getting short of breath. He reports orthopnea but no PND. \n",
      "\n",
      "He reports no fever or chills, no URI symptoms, no recent travel, no changes \n",
      "in his medications.\n",
      "\n",
      "Pt also reports ~5 episodes of chest pain in the last few weeks \n",
      "which he describes as pressure on his mid-sternum and usually \n",
      "occurs during exertion.\n",
      "\n",
      "Past Medical History:\n",
      "1. metastatic carcinoid tumor, Dx'ed 2002\n",
      "2. hypertension\n",
      "3. hyperlipidemia\n",
      "4. carotid endarterectomy 1999\n",
      "5. depression/anxiety\n",
      "\n",
      "Social History:\n",
      "Previously homeless, now lives with two daughters. Currently employed full-time.\n",
      "\n",
      "Family History:\n",
      "early CAD\n",
      "\n",
      "Brief Hospital Course:\n",
      "1. SOB: likely from CHF\n",
      "The patient was initially diuresed for mild pulmonary edema: he \n",
      "received 20 IV Lasix on night of admission and 40mg [**9-10**], with \n",
      "good UOP. On [**9-10**], pt was reporting improvement of symptoms and \n",
      "able to walk around his room with 4L O2 NC. The following day he \n",
      "reported feeling worse, with increasing SOB, and was found to \n",
      "now be in oliguric renal failure. CXR [**9-11**] 8am showed showed \n",
      "atelectasis with possible superimposed pneumonia. Emergent TTE \n",
      "showed decreased EF (30%), anteroapical infarct with \n",
      "moderate-to-severe overall left ventricular contractile \n",
      "dysfunction; bicusapid aortic valve with at least mild aortic \n",
      "stenosis. He was sent to the MICU.\n",
      "\n",
      "Medications on Admission:\n",
      "ASA 81mg po qd\n",
      "Lipitor 20mg po qpm\n",
      "\n",
      "Discharge Disposition:\n",
      "Extended Care\n",
      "Discharge Diagnosis:\n",
      "Primary: congestive heart failure\n",
      "Secondary: metastatic carcinoid tumor, hypertension, \n",
      "hyperlipidemia, diabetes mellitus type 2, basal cell carcinoma\n",
      "\n",
      "Discharge Condition:\n",
      "good, stable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(disch_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b40c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8ce46c5a154e4682122c9494fa57e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='What is the main reason the patient came to the hospital?'), RadioButtons(layout=La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_disch_summ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee314103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b1b3bea0e2450dbead9adf5e9262f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='Which of the following conditions does the patient have?.'), SelectMultiple(options…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_disch_summ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1be280a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5aa44c22824b968ef10f6e90b6f896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"The patient doesn't have any living relatives.\"), RadioButtons(layout=Layout(width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_disch_summ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "135c2c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e76516cc5584daeb39157f183cd6eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='How many episodes of chest pain has the patient had in the last few weeks?'), Texta…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_disch_summ4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ef04f",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "As you can see, there's a lot of really useful information in clinical notes. What is the advantage of documenting it using free text? What are some challenges you see with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83a221",
   "metadata": {},
   "source": [
    "## NLP\n",
    "NLP systems aim to extract information from unstructured notes like the ones above and transform that information into structured data. For example, given the sentence:\n",
    "\n",
    "--- \n",
    "Pt is a 63M w/ h/o metastatic carcinoid tumor, HTN, hyperlipidemia\n",
    "\n",
    "---\n",
    "\n",
    "We might want to create a table of diagnoses that the patient has:\n",
    "\n",
    "| patient_id | diagnosis                  |\n",
    "|------------|----------------------------|\n",
    "| 1          | metastatic carcinoid tumor |\n",
    "| 1          | HTN                        |\n",
    "| 1          | hyperlipidemia             |\n",
    "\n",
    "Or, given a set of chest imaging reports, we might want to classify each one as **positive**, **possible**, or **negative** for pneumonia:\n",
    "\n",
    "| patient_id | note_id | document_classification |\n",
    "|------------|---------|-------------------------|\n",
    "| 1          | 1       | POSSIBLE                |\n",
    "| 1          | 2       | POSITIVE                |\n",
    "| 2          | 3       | NEGATIVE                |\n",
    "\n",
    "## Design of NLP Systems\n",
    "There are two main types of NLP systems: **rule-based** and **machine learning/statistical**. We'll focus mainly rule-based in this class but will briefly go over some of the features of both.\n",
    "\n",
    "**Rule-based NLP** uses manually defined logic to extract information from text. For example, if you are classifying pneumonia from radiology reports, you could write out the terms that clinicians use to describe pneumonia and write code to identify mentions of pneumonia and other contextual information in the text. This works well when a task is highly specific (such as identifying pneumonia in text) so it's often used in applications such as clinical research projects which need information from text. But it doesn't generalize well when the task is very broad (like identifying any clinical concept in a text) or when the language is too complex.\n",
    "\n",
    "Using **statistical NLP** avoids having to write out specific logic in your code. Instead, you annotate large amounts of data and train a **machine learning model** to learn statistical patterns in the data and make predictions. Most NLP research focuses on statistical approaches, particularly [transformers](https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0) and [large language models](https://hai.stanford.edu/news/how-large-language-models-will-transform-science-society-and-ai). These can learn very sophisticated patterns and often achieve higher performance than rule-based models. But they are also very computationally expensive, difficult to interpret and understand, and require lots of annotated training data which is might be more difficult than writing out rules.\n",
    "\n",
    "Both rule-based and machine learning approaches have their advantages and disadvantages. In this class we will focus on rule-based NLP, but if you're interested in NLP beyond this course there is lots of exciting work being done in the field of statistical NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0a2fa",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Decide whether the scenarios below describe a rule-based of statistical NLP approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd62f724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126d9333eda34bda81839ee9116d8c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='To identify patients with cancer, you review notes and annotate cases of cancer in …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_rule_based_v_statistical1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43871b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb0b1eaee564b088c3b5dca71a88057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"You build a Covid-19 surveillance system with NLP which identifies patients who are…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_rule_based_v_statistical2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0985512",
   "metadata": {},
   "source": [
    "## Measuring System Performance\n",
    "No NLP system is perfect. Natural language is complex and no system will ever be able to perfectly understand what is in clinical notes. So if you're using NLP, it's important to measure how well it performs and what impact the errors would have on any analyses on your data. **False positives** occur when your system classifies a negative case as positive. **False negatives** are when your system misses a positive case and classifies it as negative.\n",
    "\n",
    "To do this, when we develop NLP systems we also perform **validation** to understand what types of errors we make. This typically involves the following steps:\n",
    "1. **Annotate** a set of notes for the concept you're interested in extracting. In this step, human reviewers define the clinical concepts they're interested in and agree upon how to identify them in texts.\n",
    "2. **Develop** your NLP system by making predictions on your annotated dataset, reviewing errors, and making improvements.\n",
    "3. **Evaluate** your system by running on a subset of notes called the *testing set* which your model/developer has never seen before. This gives you an indication of how well the system will perform on brand new data.\n",
    "\n",
    "\n",
    "When we evaluate our system, there are a few standard quantitative metrics we typically report:\n",
    "- **Precision**/**Positive Predictive Value**: This tells you how likely it is that a document classified as positive is truly positive. It is calculated as (# of true positives) / (# all predicted positives). It is equivalent to the conditional probability of a note being positive given that it was classified as positive: $$P(Y=1|X=1)$$\n",
    "where `X` is the note classification and `Y` is the true value.\n",
    "\n",
    "- **Recall**/**Sensitivity**: This tells you how well your system identifies positive cases. It is calculated as (# true positives) / (# all positives). It is also the conditional probability of a note being classified as positive given that it is actually positive: $$P(X=1|Y=1)$$\n",
    "\n",
    "- **F1-score**: This is the harmonic mean of precision and recall and is a common summary score for system performance: $$\\frac{2 * Precision * Recall}{Precision + Recall}$$\n",
    "\n",
    "We'll see an example in this module of developing and validating an NLP system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2764d55",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "The 2x2 table shows the predicted and true values of an annotated corpus of notes.\n",
    "\n",
    "| NLP      |   Positive |   Negative |\n",
    "|:---------|-----------:|-----------:|\n",
    "| Positive |         40 |         15 |\n",
    "| Negative |         10 |         35 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d161cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2132ae7a0ddb45f3982bc687fc1ced5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='What is the precision/PPV of the system?'), RadioButtons(layout=Layout(width='auto'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f8ab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca74b552c2b4f81a30dd2e46d74b8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='What is the recall/sensitivity of the system?'), RadioButtons(layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13018e33",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Let's say you've developed an NLP system for identifying Covid-19 patients from clinical texts. </br>\n",
    "Your system processes notes from 1,000 patients, of which 100 are positive and 900 are negative (i.e., prevalence is 0.1).</br>\n",
    "Your system achieves a perfect precision of 1.0 and a recall of 0.75. \n",
    "\n",
    "According to your system, what is the prevalence of Covid-19?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df41fb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13a62cbb44d46c88731e91b6cc1c813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='This hint is for the following quiz.</br><strong>Displaying hint 0/2</strong>'), Ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE HINT\n",
    "hint_covid_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ff5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80a10df8b0b4d348cf2d436fe3fd17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='What is the estimated prevalence of Covid?'), RadioButtons(layout=Layout(width='aut…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL TO SEE QUIZ\n",
    "quiz_covid_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d60169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
